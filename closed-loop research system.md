# AI closed-loop trading strategies research system

## The correct mental model

Youâ€™re building a **closed-loop research system**, not â€œadding AIâ€.

This is closer to:

> AutoML + compiler + QA + optimizer
> Than:
> ChatGPT writes strategies

---

## High-level architecture (what actually works)

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Input  â”‚  â† text / pseudocode / PineScript
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Strategy Parser  â”‚  (LLM)
â”‚ - Extract rules  â”‚
â”‚ - Normalize idea â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Strategy Builder â”‚  (LLM + templates)
â”‚ - Python code    â”‚
â”‚ - Indicator code â”‚
â”‚ - Constraints    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execution Layer  â”‚  (deterministic)
â”‚ - Backtest       â”‚
â”‚ - Error logs     â”‚
â”‚ - Metrics        â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reviewer Agent   â”‚
â”‚ - Read metrics   â”‚
â”‚ - Spot pathologies
â”‚ - Reject garbage â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optimizer Agent  â”‚
â”‚ - Param bounds   â”‚
â”‚ - Regime tests   â”‚
â”‚ - Penalize BS    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gatekeeper       â”‚
â”‚ - Accept / reject
â”‚ - Archive logic  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Only one place touches real money logic:**
ğŸ‘‰ the execution layer (pure Python, no LLM).

---

## Agent roles (THIS is critical)

### 1. Strategy Translator Agent

**Input**

* Plain English
* Pseudocode
* PineScript

**Output**

* A *formal, machine-readable strategy spec*

Example:

```json
{
  "entry": [
    "ema_fast > ema_slow",
    "rsi < 30"
  ],
  "exit": [
    "rsi > 60",
    "stoploss = 1.5 * atr"
  ],
  "timeframe": "5m",
  "filters": ["session != asia"]
}
```

This agent **does NOT write code**.
It produces **intent**, not implementation.

---

### 2. Strategy Compiler Agent

Takes the spec and:

* Maps to your backtest API
* Writes indicator functions if missing
* Enforces *your* framework rules

This agent is **sandboxed**:

* No creativity
* No â€œcleverâ€ logic
* Only allowed constructs

Think of it like a **DSL compiler**.

---

### 3. Debug / Repair Agent

Triggered only if:

* Python throws
* NaNs
* No trades
* Lookahead detected

It reads:

* Stack traces
* Logs
* Data shapes

And produces:

* Minimal diffs
  Not rewrites.

---

### 4. Strategy Reviewer Agent (MOST IMPORTANT)

This one is **hostile**.

It asks:

* Is win rate fake?
* Is trade count too low?
* Are returns coming from 2 trades?
* Does performance collapse OOS?

If yes â†’ **reject**, no optimization allowed.

---

### 5. Optimizer Agent (optional but powerful)

Only runs if reviewer approves.

Rules:

* Bounded parameters only
* Penalize:

  * Drawdown
  * Trade clustering
  * Sensitivity
* Enforce:

  * Minimum trades
  * Stability across splits

This agent **never edits logic**, only parameters.

---

## Fitness function (donâ€™t screw this up)

You already sensed this earlier, so let me be blunt:

### Sharpe is trash for what you want

A sane composite:

```txt
score =
  CAGR
- Î± * max_drawdown
+ Î² * win_rate
- Î³ * parameter_sensitivity
- Î´ * equity_curve_entropy
```

Add **hard gates**, not soft penalties:

* min trades per year
* min avg R multiple
* max DD %

If a gate fails â†’ score = -âˆ

---

## TradingView PineScript input (important)

DO NOT try to convert Pine â†’ Python directly.

Correct flow:

1. LLM extracts **logic**, not syntax
2. You re-express logic in your system
3. Ignore:

   * repainting
   * security() calls
   * barstate tricks

Otherwise youâ€™ll import garbage strategies.

---

## Tools / frameworks (no hype)

* **LLM orchestration**:

  * LangGraph

* **Execution**:

  * Pure Python + NumPy/Numba
  * Zero LLM involvement

* **Search**:

  * Bayesian optimization / CMA-ES
  * Not â€œLLM guessing numbersâ€

---

## Failure modes you MUST guard against

1. **Self-confirming loops**
   Agent optimizes â†’ reviews itself â†’ approves trash

2. **Strategy bloat**
   More indicators â‰  better
   Enforce max complexity

3. **Regime overfitting**
   Always test:

   * trend
   * chop
   * volatility spikes

4. **Narrative seduction**
   Agent explains why it â€œmakes senseâ€
   â†’ explanation â‰  edge

Kill any strategy that sounds smart but behaves fragile.

## Recommended architecture (clean, scalable)

### 1. Convert existing project into a **pure engine**

Minimal changes:

* Keep:

  * `main.py`
  * `optimize.py`
  * `indicators/`
  * `strategies/Base.py`
* Treat it as:

  > a deterministic research engine

---

### 2. Add a separate layer: `research_agent/`

```
research_agent/
â”œâ”€â”€ translator.py      # text / pine â†’ spec
â”œâ”€â”€ spec_schema.py     # validation rules
â”œâ”€â”€ compiler.py        # spec â†’ Strategy class
â”œâ”€â”€ reviewer.py        # metrics sanity checks
â”œâ”€â”€ optimizer.py       # param search (calls optimize.py)
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ specs/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ results/
```

This layer:

* Imports your engine
* Never modifies it
* Treats it as a black box

---

### 3. How they interact (very important)

```txt
User text
   â†“
Translator Agent
   â†“
Spec JSON  â† persisted, versioned
   â†“
Compiler
   â†“
Generated strategy class (temporary)
   â†“
Your existing backtest engine
   â†“
Metrics
   â†“
Reviewer / Optimizer
```

If the agent goes insane, **your engine remains sane**.

---

